import itertools
import numpy as np
from learners.learner import Classifier
from space_mat import THRESHOLDED_COUNT
from tools.featurize import convert_point_to_idx, convert_idx_to_point
import time

class ALClassifierFast2(Classifier):
    '''Active learning classifier that suggests the top n points with the highest uncertainty and high complementarity that haven't been measured yet to be measured next.
    Complementarity is judged by pairs of reaction conditions'''
    def __init__(self, space_shape:tuple, all_conditions, max_set_size, alpha_init_fun=(lambda x: np.linspace(0, 1, x, endpoint=True)), cpus=None, model_type='GP', stochastic_cond_num=None):
        super().__init__(space_shape, model_type, cpus)
        self.all_conditions = all_conditions
        self.max_set_size = max_set_size
        self.alpha_init_fun = alpha_init_fun
        self.stochastic_cond_num = stochastic_cond_num

    def exploit_fast2(self, uncertainty):
        exploit = [0] * len(uncertainty)
        t0 = time.time()

        # compute exploit val for all points
        all_reactants = list(itertools.product(*[range(s) for s in self.shape[len(self.all_conditions[0]):]]))
        for i, c1 in enumerate(self.all_conditions):
            for c2 in self.all_conditions[i+1:]:
                coverage = self.predicted_surface.score_coverage((c1, c2), THRESHOLDED_COUNT(np.prod(self.shape[len(self.all_conditions[0]):]))(.5))
                for reactant in all_reactants:
                    exploit[convert_point_to_idx(self.shape, c1 + reactant)] += coverage * (1- self.predicted_surface[(c2 + reactant)])
                    exploit[convert_point_to_idx(self.shape, c2 + reactant)] += coverage * (1- self.predicted_surface[(c1 + reactant)])
            
            for reactant in all_reactants:
                exploit[convert_point_to_idx(self.shape, c1 + reactant)] += self.predicted_surface.score_coverage((c1,), THRESHOLDED_COUNT(np.prod(self.shape[len(self.all_conditions[0]):]))(.5))

        exploit = np.divide(exploit, (len(self.all_conditions)))

        print(f"time to create exploit: {time.time() - t0}")
        t0 = time.time()

        #multiply by probablity of success for each point
        exploit = exploit * uncertainty.T[1]

        return exploit
    
    def exploit_fast2_stochastic(self, uncertainty):
        exploit = [0] * len(uncertainty)
        t0 = time.time()

        # select random set of conditions to look at
        condition_idxs = np.random.choice(len(self.all_conditions), self.stochastic_cond_num, replace=False)
        conditions = [self.all_conditions[i] for i in condition_idxs]

        other_conditions = [c for i, c in enumerate(self.all_conditions) if not i in condition_idxs]
        cond_pairs = list(itertools.combinations(conditions, 2))

        # compute exploit val for all points in conditions chosen
        all_reactants = list(itertools.product(*[range(s) for s in self.shape[len(self.all_conditions[0]):]]))
        for c in conditions:
            for c2 in other_conditions:
                coverage = self.predicted_surface.score_coverage((c, c2), THRESHOLDED_COUNT(np.prod(self.shape[len(self.all_conditions[0]):]))(.5))
                for reactant in all_reactants:
                    exploit[convert_point_to_idx(self.shape, c + reactant)] += coverage * (1- self.predicted_surface[(c2 + reactant)])
            
            for reactant in all_reactants:
                exploit[convert_point_to_idx(self.shape, c + reactant)] += self.predicted_surface.score_coverage((c,), THRESHOLDED_COUNT(np.prod(self.shape[len(self.all_conditions[0]):]))(.5))
        
        for (c1, c2) in cond_pairs:
            coverage = self.predicted_surface.score_coverage((c1, c2), THRESHOLDED_COUNT(np.prod(self.shape[len(self.all_conditions[0]):]))(.5))
            for reactant in all_reactants:
                exploit[convert_point_to_idx(self.shape, c1 + reactant)] += coverage * (1- self.predicted_surface[(c2 + reactant)])
                exploit[convert_point_to_idx(self.shape, c2 + reactant)] += coverage * (1- self.predicted_surface[(c1 + reactant)])

        exploit = np.divide(exploit, (len(self.all_conditions)))

        print(f"time to create exploit: {time.time() - t0}")
        t0 = time.time()

        #multiply by probablity of success for each point
        exploit = exploit * uncertainty.T[1]

        return exploit
        
    def suggest_next_n_points(self, X:np.ndarray, n:int, measured_indices:set)->list:
        '''next_points is a list of indices of the next points to be measured'''
        uncertainty = self.predict(X)
        
        explore_a = self.alpha_init_fun(n)
        exploit_a = 1 - explore_a

        # compute explore val for all points
        explore = 1 - (2*abs(uncertainty.T[0] - .5))

        if (self.stochastic_cond_num is not None):
            exploit = self.exploit_fast2_stochastic(uncertainty)
        else:
            # compute exploit val for all points
            exploit = self.exploit_fast2(uncertainty)

        unmeasured_points = np.array([(i, explore[i], exploit[i]) for i in range(len(uncertainty)) if i not in measured_indices], dtype=[('idx', int), ('explore', float), ('exploit', float)])

        # multiply explore and exploit by alphas, find max idx along that axis (as long as two are not the same)
        opt_vals = np.array([unmeasured_points['explore']]).T@np.array([explore_a]) + np.array([unmeasured_points['exploit']]).T@np.array([exploit_a])

        top_k_idxs = np.argpartition(opt_vals, -n, axis=0)[-n:]

        top_k_idxs = np.diagonal(top_k_idxs[np.argsort([[opt_vals[idxs[i]][i] for i in range(len(explore_a))] for idxs in top_k_idxs], axis=0, kind='stable')], axis1=1, axis2=2)

        # get unique points for all alpha values
        idxs = top_k_idxs[-1]
        best_idxs = np.full(n, -1, dtype=int)
        for i in range(len(top_k_idxs)):
            idx = idxs[i]
            if idxs[i] in best_idxs:
                j = 2
                while top_k_idxs[-1*j][i] in best_idxs:
                    j += 1
                idx = top_k_idxs[-j][i]
            best_idxs[i] = idx

        next_idxs = unmeasured_points[best_idxs]['idx'].tolist()
        print(next_idxs)
        point_uncertainties = unmeasured_points[best_idxs]['explore'].tolist()

        return uncertainty, self.predicted_surface, next_idxs, point_uncertainties
    

